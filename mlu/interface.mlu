#include <bang.h>
#include <lapacke.h>
#include <string.h>

#include <unistd.h>
#include <random> // Required for random number generation
#define MAX_NRAM_SIZE 655360
#define CLUSTER_NUM 6
#define CORE_NUM_PER_CLUSTER 4
#define POS 0

const double PI = 3.14159265358979323846;

cnrtQueue_t __queue;
__nram__ uint8_t nram_buffer[MAX_NRAM_SIZE];

__mlu_const__ float grayscale_coefficient[3] = {0.299f, 0.587f, 0.114f};
__mlu_const__ float grid_x[] = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047};

__mlu_entry__ void Kernel_rotate(int* idxs, int p_if_outbound,
                                 int src_width, int src_height, int dst_width, int dst_height,
                                 float cos_angle, float sin_angle,
                                 float cx, float cy, float new_cx, float new_cy) {
    int instr_count = 0;
    int rows_per_core = dst_height / taskDim;
    int rows_last_core = dst_height % taskDim;
    
    int row_start = taskId * rows_per_core;
    int row_end = taskId == taskDim - 1 ? dst_height : (taskId + 1) * rows_per_core;
    
    // it seems to change nothing... rows_per_turn = 9 or 1, their corresponding execution time are almost the same.
    int rows_per_turn = 7; // manually defined
    int temp_rows_last_turn = (row_end - row_start) % rows_per_turn;
    int rows_last_turn = temp_rows_last_turn == 0 ? rows_per_turn : temp_rows_last_turn;
    int chunk_size_per_turn = rows_per_turn * dst_width;
    int chunk_size_last_turn = rows_last_turn * dst_width;

    int row_last_turn = row_start + (ceil((float)(row_end - row_start) / (float)rows_per_turn) - 1) * rows_per_turn;
    
    int data_nram_num = 23000;

    int* lut = (int*)nram_buffer;
    float* xs = (float*)(lut + data_nram_num);
    float* ys = (float*)(xs + data_nram_num);
    float* src_xs = (float*)(ys + data_nram_num);
    float* src_ys = (float*)(src_xs + data_nram_num);
    int* temp1 = (int*)(src_ys + data_nram_num);
    int* temp2 = (int*)(temp1 + data_nram_num);

    float* temp3 = (float*)(temp2 + data_nram_num);
    for (int x = 0; x < dst_width; x++) temp3[x] = (float)x;
    for (int y = row_start; y < row_end; y += rows_per_turn) {
        int chunk_size = y == row_last_turn ? chunk_size_last_turn : chunk_size_per_turn;
        int rows_this_turn = y == row_last_turn ? rows_last_turn : rows_per_turn;

        // construct large vector
        for (int i = 0; i < rows_this_turn; i++) {
            __memset_nram(ys + i * dst_width, dst_width, (float)(y + i));
            __bang_move(xs + i * dst_width, temp3, dst_width * sizeof(float));
        }

        // compute nearest src_xs and src_ys
        __bang_add_scalar(src_xs, xs, -new_cx, chunk_size);
        __bang_move(src_ys, src_xs, chunk_size * sizeof(float));
        
        __bang_mul_scalar(src_xs, src_xs, cos_angle, chunk_size);
        __bang_mul_scalar(src_ys, src_ys, -sin_angle, chunk_size);

        __bang_add_scalar(ys, ys, -new_cy, chunk_size);
        __bang_mul_scalar(xs, ys, sin_angle, chunk_size);
        __bang_add(src_xs, src_xs, xs, chunk_size);
        __bang_mul_scalar(xs, ys, cos_angle, chunk_size);
        __bang_add(src_ys, src_ys, xs, chunk_size);

        __bang_add_scalar(src_xs, src_xs, cx, chunk_size);
        __bang_add_scalar(src_ys, src_ys, cy, chunk_size);

        // now start constructing lut
        // 1. & 2. type conversion and construct mask
        __bang_float2int_rm(lut, src_xs, chunk_size, POS);
        __bang_ge_scalar(temp1, lut, 0, chunk_size);
        __bang_lt_scalar(temp2, lut, src_width, chunk_size);
        __bang_band(temp1, temp1, temp2, chunk_size);

        __bang_float2int32_rm(lut, src_ys, chunk_size, POS);
        __bang_ge_scalar(temp2, lut, 0, chunk_size);
        __bang_lt_scalar(lut, lut, src_height, chunk_size);
        __bang_band(temp2, temp2, lut, chunk_size);

        // now temp1 is the mask for lut, 1 stands for valid
        __bang_band(temp1, temp1, temp2, chunk_size);

        // 3. construct raw lut
        __bang_float2int32_rm(lut, src_ys, chunk_size, POS);
        __bang_float2int32_rm(temp2, src_xs, chunk_size, POS);
        __bang_mul_scalar(lut, lut, src_width, chunk_size);
        __bang_add(lut, lut, temp2, chunk_size);
        
        __bang_mul(lut, lut, temp1, chunk_size);

        // 4. replace outbound positions with pre-prepared position `p_if_outbound`, whose value is src_size

        __memcpy(idxs + y * dst_width, lut, chunk_size * sizeof(int), NRAM2GDRAM);
    }
}


__mlu_entry__ void Kernel_erase(uint8_t* data, uint8_t v, int src_width, int width, int height, int channels) {
    int rows_per_core = height / taskDim;
    int rows_last_core = height % taskDim;
    if (rows_last_core < rows_per_core) rows_last_core += rows_per_core;

    int row_start = taskId * rows_per_core;
    int row_end = taskId == taskDim - 1 ? height : (taskId + 1) * rows_per_core;

    int num_per_chunk = rows_per_core * src_width * channels;
    int num_curr_chunk = (taskId == taskDim - 1 ? rows_last_core : rows_per_core) * src_width * channels;

    int data_nram_num = 10000;

    // count = (2048 * 2048 * 3 * 2 + 2048 * 2048 * 3 * 1)
    uint8_t* data_local = (uint8_t*)nram_buffer;
    __memcpy(data_local, data + num_per_chunk * taskId,
             num_curr_chunk * sizeof(uint8_t), GDRAM2NRAM);

    uint8_t* curr = data_local;
    for (int row = row_start; row < row_end; row++) {
        __bang_write_value(curr, width * channels, v);
        curr += src_width * channels;
    }

    __memcpy(data + num_per_chunk * taskId, data_local,
             num_curr_chunk * sizeof(uint8_t), NRAM2GDRAM);
}



__mlu_entry__ void Kernel_affine(int *idxs, int p_if_outbound,
                                 float a, float b, float c,
                                 float d, float e, float f,
                                 int height, int width, int channels)
{    
    int instr_count = 0;
    int rows_per_core = height / taskDim;
    int rows_last_core = height % taskDim;
    int row_start = taskId * rows_per_core;
    int row_end = taskId == taskDim - 1 ? height : (taskId + 1) * rows_per_core;
    
    int data_nram_num = 3000;

    float* xs = (float*)nram_buffer;
    float* ys = (float*)(xs + data_nram_num);
    float* src_xs = (float*)(ys + data_nram_num);
    float* src_ys = (float*)(src_xs + data_nram_num);
    float* temp = (float*)(src_ys + data_nram_num);

    int* lut = (int*)(temp + data_nram_num);
    int* temp1 = (int*)(lut + data_nram_num);
    int* temp2 = (int*)(temp1 + data_nram_num);
    
    for (int x = 0; x < width; x++)
        xs[x] = (float)x;
    // count = 2048 * 2048 * (2 * 2 + 3 * 15 + 4 * 6 + 2) + 2048 * 24 * 2 = 281,018,368
    for (int y = row_start; y < row_end; y++)
    {
        __memset_nram(ys, width, (float)y);

        __bang_mul_scalar(src_xs, xs, a, width);
        __bang_mul_scalar(temp, ys, b, width);
        __bang_add(src_xs, src_xs, temp, width);
        __bang_add_scalar(src_xs, src_xs, c, width);

        __bang_mul_scalar(src_ys, xs, d, width);
        __bang_mul_scalar(temp, ys, e, width);
        __bang_add(src_ys, src_ys, temp, width);
        __bang_add_scalar(src_ys, src_ys, f, width);

        // construct mask
        __bang_float2int_rm(lut, src_xs, width, POS);
        __bang_ge_scalar(temp1, lut, 0, width);
        __bang_lt_scalar(temp2, lut, width, width);
        __bang_band(temp1, temp1, temp2, width);

        __bang_float2int32_rm(lut, src_ys, width, POS);
        __bang_ge_scalar(temp2, lut, 0, width);
        __bang_lt_scalar(lut, lut, height, width);
        __bang_band(temp2, temp2, lut, width);

        // now temp1 is the mask for lut, 1 stands for valid
        __bang_band(temp1, temp1, temp2, width);

        // construct raw lut
        __bang_float2int32_rm(lut, src_ys, width, POS);
        __bang_float2int32_rm(temp2, src_xs, width, POS);
        __bang_mul_scalar(lut, lut, width, width);
        __bang_add(lut, lut, temp2, width);
        
        // filter
        __bang_mul(lut, lut, temp1, width);
        
        // move
        __memcpy(idxs + y * width, lut, width * sizeof(int), NRAM2GDRAM);
    }
}





__mlu_global__ void gray_kernel(uint8_t* dst, const uint8_t* src, const int data_num, const int output_channels) {
    int32_t data_per_core = data_num / taskDim;
    int32_t data_last_core = data_per_core + data_num % taskDim;
    const uint8_t *src_offset = src + taskId * data_per_core * 3;
    uint8_t *dst_offset = dst + taskId * data_per_core * output_channels;

    if (taskId == taskDim - 1) {
        data_per_core = data_last_core;
    }

    const unsigned int data_nram_num = MAX_NRAM_SIZE / sizeof(float) / 4;
    const unsigned int loop_num = data_per_core / data_nram_num;
    const unsigned int rem_nram_num = data_per_core % data_nram_num;

    float *float_src_nram = (float *)nram_buffer;
    float *float_dst_nram = (float *)(float_src_nram + 3 * data_nram_num);
    uint8_t *uint8_src_nram = (uint8_t *)float_dst_nram;
    uint8_t *uint8_dst_nram = (uint8_t *)nram_buffer;

    __wram__ float conv_kernel[48];      // 48 is for byte alignment
    __memcpy(conv_kernel, grayscale_coefficient, 4 * sizeof(float), GDRAM2WRAM, 64, sizeof(float), 2);
    
    __wram__ int8_t mat[256*256*4];
    int8_t *int8_src_nram = (int8_t *)nram_buffer;
    int16_t *int16_dst_nram = (int16_t *)float_dst_nram;
    __bang_matmul(int16_dst_nram, int8_src_nram, mat, 256, 256, 256, 0);

    for (unsigned int i = 0; i < loop_num; i++) {
        __memcpy(uint8_src_nram, src_offset + i * 3 * data_nram_num, 3 * data_nram_num * sizeof(uint8_t), GDRAM2NRAM);
        __bang_uchar2float(float_src_nram, uint8_src_nram, 3 * data_nram_num);
        __bang_conv(float_dst_nram, float_src_nram, conv_kernel, 3, 1, data_nram_num, 1, 1, 1, 1, 1);
        __bang_float2uchar_rm(uint8_dst_nram, float_dst_nram, data_nram_num);
        if (output_channels == 3) {
            __memcpy(uint8_dst_nram + data_nram_num, uint8_dst_nram, data_nram_num * sizeof(uint8_t), NRAM2NRAM);
            __memcpy(uint8_dst_nram + 2 * data_nram_num, uint8_dst_nram, data_nram_num * sizeof(uint8_t), NRAM2NRAM);
            __bang_transpose(uint8_dst_nram + 3 * data_nram_num, uint8_dst_nram, 3, data_nram_num);
            uint8_dst_nram += 3 * data_nram_num;
        }
        __memcpy(dst_offset + i * output_channels * data_nram_num, uint8_dst_nram, output_channels * data_nram_num * sizeof(uint8_t), NRAM2GDRAM);
        uint8_dst_nram = (uint8_t *)nram_buffer;
    }

    if (rem_nram_num != 0) {
        __memcpy(uint8_src_nram, src_offset + loop_num * 3 * data_nram_num, 3 * rem_nram_num * sizeof(uint8_t), GDRAM2NRAM);
        __bang_uchar2float(float_src_nram, uint8_src_nram, 3 * rem_nram_num);
        __bang_conv(float_dst_nram, float_src_nram, conv_kernel, 3, 1, rem_nram_num, 1, 1, 1, 1, 1);
        __bang_float2uchar_rm(uint8_dst_nram, float_dst_nram, rem_nram_num);
        if (output_channels == 3) {
            __memcpy(uint8_dst_nram + rem_nram_num, uint8_dst_nram, rem_nram_num * sizeof(uint8_t), NRAM2NRAM);
            __memcpy(uint8_dst_nram + 2 * rem_nram_num, uint8_dst_nram, rem_nram_num * sizeof(uint8_t), NRAM2NRAM);
            __bang_transpose(uint8_dst_nram + 3 * rem_nram_num, uint8_dst_nram, 3, rem_nram_num);
            uint8_dst_nram += 3 * rem_nram_num;
        }
        __memcpy(dst_offset + loop_num * output_channels * data_nram_num, uint8_dst_nram, output_channels * rem_nram_num * sizeof(uint8_t), NRAM2GDRAM);
    }
}

__mlu_global__ void pad_kernel(uint8_t *dst, const uint8_t *src, const uint8_t *pad, const int height, const int width, const int left, const int right) {
    int rows_per_core = height / taskDim;
    const int rows_last_core = rows_per_core + height % taskDim;

    const int dst_width = width + left + right;
    const uint8_t *src_offset = src + taskId * rows_per_core * width * 3;
    uint8_t *dst_offset = dst + taskId * rows_per_core * dst_width * 3;

    __wram__ int8_t mat[256*256*4];
    float *float_src_nram = (float *)nram_buffer;
    float *float_dst_nram = (float *)(float_src_nram + 3 * 1000);
    int8_t *int8_src_nram = (int8_t *)nram_buffer;
    int16_t *int16_dst_nram = (int16_t *)float_dst_nram;
    __bang_matmul(int16_dst_nram, int8_src_nram, mat, 256, 256, 256, 0);

    if (taskId == taskDim - 1) {
        rows_per_core = rows_last_core;
    }

    // Pads the left and right borders of the original image
    for (int i = 0; i < rows_per_core; ++i) {
        __memcpy(dst_offset + i * 3 * dst_width, pad, 3 * left * sizeof(uint8_t), GDRAM2GDRAM);
        __memcpy(dst_offset + i * 3 * dst_width + 3 * left, src_offset + i * 3 * width, 3 * width * sizeof(uint8_t), GDRAM2GDRAM);
        __memcpy(dst_offset + (i + 1) * 3 * dst_width - 3 * right, pad, 3 * right * sizeof(uint8_t), GDRAM2GDRAM);
    }
}

void getPerspectiveTransform(const int *src, const int *dst, float *TransformMatrix) {
    /* 
     * Calculates coefficients of perspective transformation
     * which maps (xi,yi) to (ui,vi), (i=1,2,3,4):
     *
     *      c00*xi + c01*yi + c02
     * ui = ---------------------
     *      c20*xi + c21*yi + c22
     *
     *      c10*xi + c11*yi + c12
     * vi = ---------------------
     *      c20*xi + c21*yi + c22
     *
     * Coefficients are calculated by solving linear system:
     * / x0 y0  1  0  0  0 -x0*u0 -y0*u0 \ /c00\ /u0\
     * | x1 y1  1  0  0  0 -x1*u1 -y1*u1 | |c01| |u1|
     * | x2 y2  1  0  0  0 -x2*u2 -y2*u2 | |c02| |u2|
     * | x3 y3  1  0  0  0 -x3*u3 -y3*u3 |.|c10|=|u3|,
     * |  0  0  0 x0 y0  1 -x0*v0 -y0*v0 | |c11| |v0|
     * |  0  0  0 x1 y1  1 -x1*v1 -y1*v1 | |c12| |v1|
     * |  0  0  0 x2 y2  1 -x2*v2 -y2*v2 | |c20| |v2|
     * \  0  0  0 x3 y3  1 -x3*v3 -y3*v3 / \c21/ \v3/
     *
     * where:
     *   cij - matrix coefficients, c22 = 1
     * 
     * Args:
     *    src (int[4][2]): 2-D array containing four corners of the original image.
     *    dst (int[4][2]): 2-D array containing four corners of the transformed image.
     *    TransformMatrix (float[3][3]): 3x3 perspective transformation matrix.
     * 
     */


    float A[8][8] = {0};

    for(int i = 0; i < 4; ++i) {
        int x = i << 1;
        int y = x + 1;
        A[i][0] = A[i+4][3] = src[x];
        A[i][1] = A[i+4][4] = src[y];
        A[i][2] = A[i+4][5] = 1;
        A[i][6] = -src[x] * dst[x];
        A[i][7] = -src[y] * dst[x];
        A[i+4][6] = -src[x] * dst[y];
        A[i+4][7] = -src[y] * dst[y];
        TransformMatrix[i] = dst[x];
        TransformMatrix[i+4] = dst[y];
    }

    int ipiv[8];
    int info = LAPACKE_sgesv(LAPACK_ROW_MAJOR, 8, 1, A[0], 8, ipiv, TransformMatrix, 1);
    if (info != 0) {
        throw std::runtime_error("LAPACKE_sgesv failed, info = " + std::to_string(info));
    }
    TransformMatrix[8] = 1.0f;

}

__mlu_global__ void perspective_kernel(uint32_t *transformed_Grid, const float *transform_Matrix, const int rows, const int cols) {
    // Divide the image into rows and assign them to each core for processing
    unsigned int rows_per_core = rows / taskDim;
    const unsigned int rows_last_core = rows_per_core + rows % taskDim;
    unsigned int grid_y = taskId * rows_per_core;

    if (taskId == taskDim - 1) {
        rows_per_core = rows_last_core;
    }

    // Copy the perspective transformation matrix to WRAM space
    __wram__ float wram_transformMatrix[48];   // 48 = 64 x 3 / sizeof(float), the extra space is for byte alignment
    __memcpy(wram_transformMatrix, transform_Matrix, 4 * sizeof(float), GDRAM2WRAM, 64, 3 * sizeof(float), 2);

    // Due to the limited space of NRAM, the data will be copied in batches into NRAM for vector calculation
    const unsigned int rows_per_nram = (MAX_NRAM_SIZE / sizeof(float) - cols) / 6 / cols;
    const unsigned int loop_num = rows_per_core / rows_per_nram;
    const unsigned int rem_rows = rows_per_core % rows_per_nram;
    const unsigned int data_nram_num = rows_per_nram * cols;
    const unsigned int rem_nram_num = rem_rows * cols;

    __wram__ int8_t mat[256*256*4];
    float *float_src_nram = (float *)nram_buffer;
    float *float_dst_nram = (float *)(float_src_nram + 3 * 1000);
    int8_t *int8_src_nram = (int8_t *)nram_buffer;
    int16_t *int16_dst_nram = (int16_t *)float_dst_nram;
    __bang_matmul(int16_dst_nram, int8_src_nram, mat, 256, 256, 256, 0);

    /* nram space usage
     * |+++++grid_x+++++|+++++grid_y+++++|+++++grid_1+++++|----------------|----------------|----------------|
     * |-----grid_x-----|-----grid_y-----|-----grid_1-----|+++++++++++transpose(data_nram_num x 3)+++++++++++|
     * |+++++++++++++matmul(data_nram_num x 3)++++++++++++|-----------transpose(data_nram_num x 3)-----------|
     * |-------------matmul(data_nram_num x 3)------------|+++++++++++transpose(3 x data_nram_num)+++++++++++|
     * |-------------matmul(data_nram_num x 3)------------|++++grid_u/w++++|++++grid_v/w++++|++++grid_1/w++++|
     * |+++++comp_lt++++|+++++comp_ge++++|----------------|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |+++++comp_x+++++|-----comp_ge----|----------------|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |-----comp_x-----|+++++comp_lt++++|+++++comp_ge++++|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |-----comp_x-----|+++++comp_y+++++|-----comp_ge----|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |++++++comp++++++|-----comp_y-----|-----comp_ge----|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |------comp------|+++++grid_x+++++|+++++grid_y+++++|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * 
     * (0) nearest interpolation
     * |++++++grid++++++|+++++grid_x+++++|+++++grid_y+++++|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |+++++grid_B+++++|+++++grid_G+++++|+++++grid_R+++++|----grid_u/w----|----grid_v/w----|----grid_1/w----|
     * |-----grid_B-----|-----grid_G-----|-----grid_R-----|+++++++++++transpose(data_nram_num x 3)+++++++++++|
     */

    __memcpy(nram_buffer, grid_x, cols * sizeof(float), GDRAM2NRAM);

    float *float_nram0 = (float *)(nram_buffer) + cols;
    float *float_nram1 = (float *)(float_nram0 + data_nram_num);
    float *float_nram2 = (float *)(float_nram1 + data_nram_num);
    float *float_nram3 = (float *)(float_nram2 + data_nram_num);
    float *float_nram4 = (float *)(float_nram3 + data_nram_num);
    float *float_nram5 = (float *)(float_nram4 + data_nram_num);

    uint32_t *uint32_nram0 = (uint32_t *)float_nram0;
    uint32_t *uint32_nram1 = (uint32_t *)float_nram1;
    uint32_t *uint32_nram2 = (uint32_t *)float_nram2;
    uint32_t *uint32_nram3 = (uint32_t *)float_nram3;

    uint32_t *grid0 = transformed_Grid + 3 * grid_y * cols;
    
    for (unsigned int i = 0; i < loop_num; ++i) {
        for (unsigned int j = 0; j < rows_per_nram; ++j) {
            __memcpy(float_nram0 + j * cols, nram_buffer, cols * sizeof(float), NRAM2NRAM);
            __memset_nram(float_nram1 + j * cols, cols, (float)(grid_y + j));
        }
        __memset_nram(float_nram2, data_nram_num, 1.0f);
        grid_y += rows_per_nram;

        __bang_transpose(float_nram3, float_nram0, 3, data_nram_num);
        __bang_matmul(float_nram0, float_nram3, wram_transformMatrix, data_nram_num, 3, 3);
        __bang_transpose(float_nram3, float_nram0, data_nram_num, 3);

        __bang_recip(float_nram5, float_nram5, data_nram_num);
        __bang_mul(float_nram3, float_nram3, float_nram5, data_nram_num);
        __bang_mul(float_nram4, float_nram4, float_nram5, data_nram_num);

        __bang_lt_scalar(float_nram0, float_nram3, (float)cols, data_nram_num);
        __bang_ge_scalar(float_nram1, float_nram3, 0.0f, data_nram_num);
        __bang_band((char *)float_nram0, (char *)float_nram0, (char *)float_nram1, data_nram_num * sizeof(float));

        __bang_lt_scalar(float_nram1, float_nram4, (float)rows, data_nram_num);
        __bang_ge_scalar(float_nram2, float_nram4, 0.0f, data_nram_num);
        __bang_band((char *)float_nram1, (char *)float_nram1, (char *)float_nram2, data_nram_num * sizeof(float));

        __bang_band((char *)float_nram0, (char *)float_nram0, (char *)float_nram1, data_nram_num * sizeof(float));

        __bang_mul(float_nram1, float_nram0, float_nram3, data_nram_num);
        __bang_mul(float_nram2, float_nram0, float_nram4, data_nram_num);

        // NEAREST
        __bang_float2uint32_rm(uint32_nram1, float_nram1, 2 * data_nram_num, 0);

        __bang_fusion(FUSION_FMA, uint32_nram0, uint32_nram2, (uint32_t)cols, uint32_nram1, data_nram_num, data_nram_num);
        
        __bang_mul_scalar(uint32_nram0, uint32_nram0, 3, data_nram_num);
        __bang_add_scalar(uint32_nram1, uint32_nram0, 1, data_nram_num);
        __bang_add_scalar(uint32_nram2, uint32_nram0, 2, data_nram_num);

        __bang_transpose(uint32_nram3, uint32_nram0, 3, data_nram_num);
        __memcpy(grid0 + i * 3 * data_nram_num, uint32_nram3, 3 * data_nram_num * sizeof(uint32_t), NRAM2GDRAM);
    }

    if (rem_nram_num != 0) {
        float_nram1 = (float *)(float_nram0 + rem_nram_num);
        float_nram2 = (float *)(float_nram1 + rem_nram_num);
        float_nram3 = (float *)(float_nram2 + rem_nram_num);
        float_nram4 = (float *)(float_nram3 + rem_nram_num);
        float_nram5 = (float *)(float_nram4 + rem_nram_num);

        uint32_nram1 = (uint32_t *)float_nram1;
        uint32_nram2 = (uint32_t *)float_nram2;
        uint32_nram3 = (uint32_t *)float_nram3;

        for (unsigned int j = 0; j < rem_rows; ++j) {
            __memcpy(float_nram0 + j * cols, nram_buffer, cols * sizeof(float), NRAM2NRAM);
            __memset_nram(float_nram1 + j * cols, cols, (float)(grid_y + j));
        }
        __memset_nram(float_nram2, rem_nram_num, 1.0f);

        __bang_transpose(float_nram3, float_nram0, 3, rem_nram_num);
        __bang_matmul(float_nram0, float_nram3, wram_transformMatrix, rem_nram_num, 3, 3);
        __bang_transpose(float_nram3, float_nram0, rem_nram_num, 3);

        __bang_recip(float_nram5, float_nram5, rem_nram_num);
        __bang_mul(float_nram3, float_nram3, float_nram5, rem_nram_num);
        __bang_mul(float_nram4, float_nram4, float_nram5, rem_nram_num);
        
        __bang_lt_scalar(float_nram0, float_nram3, (float)cols, rem_nram_num);
        __bang_ge_scalar(float_nram1, float_nram3, 0.0f, rem_nram_num);
        __bang_band((char *)float_nram0, (char *)float_nram0, (char *)float_nram1, rem_nram_num * sizeof(float));

        __bang_lt_scalar(float_nram1, float_nram4, (float)rows, rem_nram_num);
        __bang_ge_scalar(float_nram2, float_nram4, 0.0f, rem_nram_num);
        __bang_band((char *)float_nram1, (char *)float_nram1, (char *)float_nram2, rem_nram_num * sizeof(float));

        __bang_band((char *)float_nram0, (char *)float_nram0, (char *)float_nram1, rem_nram_num * sizeof(float));

        __bang_mul(float_nram1, float_nram0, float_nram3, rem_nram_num);
        __bang_mul(float_nram2, float_nram0, float_nram4, rem_nram_num);

        // NEAREST
        __bang_float2uint32_rm(uint32_nram1, float_nram1, 2 * rem_nram_num, 0);
        
        __bang_fusion(FUSION_FMA, uint32_nram0, uint32_nram2, (uint32_t)cols, uint32_nram1, rem_nram_num, rem_nram_num);
        
        __bang_mul_scalar(uint32_nram0, uint32_nram0, 3, rem_nram_num);
        __bang_add_scalar(uint32_nram1, uint32_nram0, 1, rem_nram_num);
        __bang_add_scalar(uint32_nram2, uint32_nram0, 2, rem_nram_num);

        __bang_transpose(uint32_nram3, uint32_nram0, 3, rem_nram_num);
        __memcpy(grid0 + loop_num * 3 * data_nram_num, uint32_nram3, 3 * rem_nram_num * sizeof(uint32_t), NRAM2GDRAM);
    }
}

__mlu_global__ void Flip_Kernel(uint8_t* dst, const uint8_t* src,const int width,const int height) {
    //printf("t %d",taskId);
    const uint8_t *src_offset = src + taskId * width*3;
    uint8_t *dst_offset = dst + (height-taskId) * width*3;
    //uint8_t *int_src_nram = (uint8_t *)nram_buffer;
    uint8_t* int_src_nram = (uint8_t*)nram_buffer;
    uint8_t* int_dst_nram = (uint8_t*)(nram_buffer+7000);
    __memcpy(int_src_nram, src_offset, width * sizeof(uint8_t)*3, GDRAM2NRAM);
    __bang_move(int_dst_nram,int_src_nram, 3 * width);
    __memcpy(dst_offset, int_dst_nram, width * sizeof(uint8_t)*3, NRAM2GDRAM);
    //__bang_move(dst_offset,int_src_nram, 3 * width);

}

typedef unsigned char uchar;
__nram__ float min_index[1];
__nram__ float max_index[1];
__mlu_global__ void resizeNearestKernel(uchar* dst, const uchar* src, const uint32_t* index, uint src_size, uint dst_size) {

    const unsigned int data_nram_num = MAX_NRAM_SIZE / 11;

    const int chunk_size = data_nram_num / (src_size/dst_size*2);
    const int index_chunk_size = chunk_size / sizeof(uint32_t);
    const int rows_per_core = dst_size / taskDim;
    const int rows_last_core = rows_per_core + (dst_size % taskDim);
    const int row_begin = taskId * rows_per_core;

    uchar *src1 = (uchar *)nram_buffer;
    int *src2 = (int *)(src1 + data_nram_num);
    uint32_t *index1 = (uint32_t *)(src2+data_nram_num);
    float *index2 = (float *)(index1+data_nram_num);
    const int current_rows = (taskId == taskDim - 1) ? rows_last_core : rows_per_core;

    for (int i = row_begin; i < row_begin + current_rows; i += index_chunk_size) {
        int current_index_chunk_size = (i + index_chunk_size > dst_size) ? (dst_size - i) : index_chunk_size;

        // Copy current index chunk to NRAM
        __memcpy(index1, index + i, current_index_chunk_size * sizeof(uint32_t), GDRAM2NRAM);

        // Find min and max indices in the current chunk
        __bang_uint322float( index2,  index1, current_index_chunk_size, 0);
        __bang_argmax( max_index, index2,current_index_chunk_size);
        __bang_argmin( min_index, index2,current_index_chunk_size);

        // Ensure indices are within the source image range
        if (max_index[0] >= src_size) {
            max_index[0] = src_size - 1;
        }

        // Calculate required source data range
        int src_chunk_start = (int)min_index[0];
        int src_chunk_end =(int) max_index[0] + 1;
        int src_chunk_size = src_chunk_end - src_chunk_start;

        // Ensure the source chunk size does not exceed NRAM size
        if (src_chunk_size > data_nram_num) {
            src_chunk_size = data_nram_num;
        }

        // Copy required source data to NRAM
        __memcpy(src1, src + src_chunk_start, src_chunk_size * sizeof(uchar), GDRAM2NRAM);
        __bang_uchar2int32(src2, src1, src_chunk_size, 0);

        // Adjust indices to fit the current chunk's data range
        __bang_add_scalar(index1, index1, (-1) * (int)min_index[0], current_index_chunk_size);

        // Perform LUT operation
        __bang_lut(src2, index1, src2, current_index_chunk_size, src_chunk_size);

        // Convert results back to uchar and copy to GDRAM
        __bang_int322uchar(src1, src2, current_index_chunk_size, 0);
        __memcpy(dst + i, src1, current_index_chunk_size * sizeof(uchar), NRAM2GDRAM);
    }

    /*int data_num_mlu = mul * mul;
    int32_t data_per_core_mlu = data_num_mlu / taskDim;
    int32_t data_last_core_mlu = data_per_core_mlu + data_num_mlu % taskDim;
    const float* src0_offset_mlu = src0_mlu + taskId * data_per_core_mlu;
    const float* src1_offset_mlu = src1_mlu + taskId * data_per_core_mlu;
    float* dst_offset_mlu = dst_mlu + taskId * data_per_core_mlu;

    if (taskId == taskDim - 1) {
        data_per_core_mlu = data_last_core_mlu;
    }

    const unsigned int data_nram_num_mlu = 256*256;
    const unsigned int loop_num_mlu = data_per_core_mlu / data_nram_num_mlu;
    const unsigned int rem_nram_num_mlu = data_per_core_mlu % data_nram_num_mlu;  
    
    float *float_src0_nram_mlu = (float *)(nram_buffer);
    float *float_dst_nram_mlu = (float *)(nram_buffer);
    __wram__ float float_src1_nram_mlu[data_nram_num_mlu];

    for (unsigned int i = 0; i < loop_num_mlu; ++i){
        __memcpy(float_src0_nram_mlu, src0_offset_mlu + i * data_nram_num_mlu, data_nram_num_mlu * sizeof(float), GDRAM2NRAM);
        __memcpy(float_src1_nram_mlu, src1_offset_mlu + i * data_nram_num_mlu, data_nram_num_mlu * sizeof(float), GDRAM2WRAM);
        __bang_matmul(float_dst_nram_mlu, float_src0_nram_mlu, float_src1_nram_mlu, 256, 256, 256);
        __memcpy(dst_offset_mlu + i * data_nram_num_mlu, float_dst_nram_mlu, data_nram_num_mlu * sizeof(float), NRAM2GDRAM);
    }
    if (rem_nram_num_mlu != 0){
        __memcpy(float_src0_nram_mlu, src0_offset_mlu + loop_num_mlu * rem_nram_num_mlu, rem_nram_num_mlu * sizeof(float), GDRAM2NRAM);
        __memcpy(float_src1_nram_mlu, src1_offset_mlu + loop_num_mlu * rem_nram_num_mlu, rem_nram_num_mlu * sizeof(float), GDRAM2WRAM);
        __bang_matmul(float_dst_nram_mlu, float_src0_nram_mlu, float_src1_nram_mlu, 256, 256, 256);
        __memcpy(dst_offset_mlu + loop_num_mlu * rem_nram_num_mlu, float_dst_nram_mlu, rem_nram_num_mlu * sizeof(float), NRAM2GDRAM);
    }*/
}

__mlu_global__ void adjustContrastKernel(uint8_t* dst, const uint8_t* src, const int data_num, const float alpha) {

    int32_t data_per_core = data_num / taskDim;
    int32_t data_last_core = data_per_core + data_num % taskDim;
    const uint8_t* src_offset = src + taskId * data_per_core;
    uint8_t* dst_offset = dst + taskId * data_per_core;

    if (taskId == taskDim - 1) {
        data_per_core = data_last_core;
    }

    const unsigned int data_nram_num = MAX_NRAM_SIZE / (sizeof(float) + sizeof(uint8_t));
    const unsigned int loop_num = data_per_core / data_nram_num;
    const unsigned int rem_nram_num = data_per_core % data_nram_num;

    uint8_t *uint8_src_nram = (uint8_t *)nram_buffer;
    uint8_t *uint8_dst_nram = (uint8_t *)nram_buffer;
    float *float_src_nram = (float *)(nram_buffer + data_nram_num);
    float *float_dst_nram = (float *)float_src_nram;

    for (unsigned int i = 0; i < loop_num; i++) {
        __memcpy(uint8_src_nram, src_offset + i * data_nram_num, data_nram_num * sizeof(uint8_t), GDRAM2NRAM);
        __bang_uchar2float(float_src_nram, uint8_src_nram, data_nram_num);
        __bang_add_scalar(float_dst_nram, float_src_nram, -128.0f, data_nram_num);
	    __bang_mul_scalar(float_dst_nram, float_dst_nram, alpha, data_nram_num);
	    __bang_add_scalar(float_dst_nram, float_dst_nram, 128.0f, data_nram_num);
        __bang_float2uchar(uint8_dst_nram, float_dst_nram, data_nram_num);
        __memcpy(dst_offset + i * data_nram_num, uint8_dst_nram, data_nram_num * sizeof(uint8_t), NRAM2GDRAM);
    }

    if (rem_nram_num != 0) {
        __memcpy(uint8_src_nram, src_offset + loop_num * data_nram_num, rem_nram_num * sizeof(uint8_t), GDRAM2NRAM);
        __bang_uchar2float(float_src_nram, uint8_src_nram, rem_nram_num);
        __bang_add_scalar(float_dst_nram, float_src_nram, -128.0f, rem_nram_num);
        __bang_mul_scalar(float_dst_nram, float_dst_nram, alpha, rem_nram_num);
        __bang_add_scalar(float_dst_nram, float_dst_nram, 128.0f, rem_nram_num);
        __bang_float2uchar(uint8_dst_nram, float_dst_nram, rem_nram_num);
        __memcpy(dst_offset + loop_num * data_nram_num, uint8_dst_nram, rem_nram_num * sizeof(uint8_t), NRAM2GDRAM);
    }

    /*int data_num_mlu = mul * mul;
    int32_t data_per_core_mlu = data_num_mlu / taskDim;
    int32_t data_last_core_mlu = data_per_core_mlu + data_num_mlu % taskDim;
    const float* src0_offset_mlu = src0_mlu + taskId * data_per_core_mlu;
    const float* src1_offset_mlu = src1_mlu + taskId * data_per_core_mlu;
    float* dst_offset_mlu = dst_mlu + taskId * data_per_core_mlu;

    if (taskId == taskDim - 1) {
        data_per_core_mlu = data_last_core_mlu;
    }

    const unsigned int data_nram_num_mlu = 256*256;
    const unsigned int loop_num_mlu = data_per_core_mlu / data_nram_num_mlu;
    const unsigned int rem_nram_num_mlu = data_per_core_mlu % data_nram_num_mlu;  
    
    float *float_src0_nram_mlu = (float *)(nram_buffer);
    float *float_dst_nram_mlu = (float *)(nram_buffer);
    __wram__ float float_src1_nram_mlu[data_nram_num_mlu];

    for (unsigned int i = 0; i < loop_num_mlu; ++i){
        __memcpy(float_src0_nram_mlu, src0_offset_mlu + i * data_nram_num_mlu, data_nram_num_mlu * sizeof(float), GDRAM2NRAM);
        __memcpy(float_src1_nram_mlu, src1_offset_mlu + i * data_nram_num_mlu, data_nram_num_mlu * sizeof(float), GDRAM2WRAM);
        __bang_matmul(float_dst_nram_mlu, float_src0_nram_mlu, float_src1_nram_mlu, 256, 256, 256);
        __memcpy(dst_offset_mlu + i * data_nram_num_mlu, float_dst_nram_mlu, data_nram_num_mlu * sizeof(float), NRAM2GDRAM);
    }
    if (rem_nram_num_mlu != 0){
        __memcpy(float_src0_nram_mlu, src0_offset_mlu + loop_num_mlu * rem_nram_num_mlu, rem_nram_num_mlu * sizeof(float), GDRAM2NRAM);
        __memcpy(float_src1_nram_mlu, src1_offset_mlu + loop_num_mlu * rem_nram_num_mlu, rem_nram_num_mlu * sizeof(float), GDRAM2WRAM);
        __bang_matmul(float_dst_nram_mlu, float_src0_nram_mlu, float_src1_nram_mlu, 256, 256, 256);
        __memcpy(dst_offset_mlu + loop_num_mlu * rem_nram_num_mlu, float_dst_nram_mlu, rem_nram_num_mlu * sizeof(float), NRAM2GDRAM);
    }*/

}

__mlu_global__ void adjustBrightnessKernel(uint8_t* dst, const uint8_t* src, const int data_num, const float alpha) {

    int32_t data_per_core = data_num / taskDim;
    int32_t data_last_core = data_per_core + data_num % taskDim;
    const uint8_t* src_offset = src + taskId * data_per_core;
    uint8_t* dst_offset = dst + taskId * data_per_core;

    if (taskId == taskDim - 1) {
        data_per_core = data_last_core;
    }

    const unsigned int data_nram_num = MAX_NRAM_SIZE / (sizeof(float) + sizeof(uint8_t));
    const unsigned int loop_num = data_per_core / data_nram_num;
    const unsigned int rem_nram_num = data_per_core % data_nram_num;


    uint8_t *uint8_src_nram = (uint8_t *)nram_buffer;
    uint8_t *uint8_dst_nram = (uint8_t *)nram_buffer;
    float *float_src_nram = (float *)(nram_buffer + data_nram_num);
    float *float_dst_nram = (float *)float_src_nram;

    for (unsigned int i = 0; i < loop_num; i++) {
        __memcpy(uint8_src_nram, src_offset + i * data_nram_num, data_nram_num * sizeof(uint8_t), GDRAM2NRAM);
	    __bang_uchar2float(float_src_nram, uint8_src_nram, data_nram_num);
        __bang_mul_scalar(float_dst_nram, float_src_nram, alpha, data_nram_num);
	    __bang_float2uchar(uint8_dst_nram, float_dst_nram, data_nram_num);
        __memcpy(dst_offset + i * data_nram_num, uint8_dst_nram, data_nram_num * sizeof(uint8_t), NRAM2GDRAM);
    }

    if (rem_nram_num != 0) {
	    __memcpy(uint8_src_nram, src_offset + loop_num * data_nram_num, rem_nram_num * sizeof(uint8_t), GDRAM2NRAM);
        __bang_uchar2float(float_src_nram, uint8_src_nram, rem_nram_num);
        __bang_mul_scalar(float_dst_nram, float_src_nram, alpha, rem_nram_num);
        __bang_float2uchar(uint8_dst_nram, float_dst_nram, rem_nram_num);
        __memcpy(dst_offset + loop_num * data_nram_num, uint8_dst_nram, rem_nram_num * sizeof(uint8_t), NRAM2GDRAM);
    }
    /*
    int data_num_mlu = mul * mul;
    int32_t data_per_core_mlu = data_num_mlu / taskDim;
    int32_t data_last_core_mlu = data_per_core_mlu + data_num_mlu % taskDim;
    const float* src0_offset_mlu = src0_mlu + taskId * data_per_core_mlu;
    const float* src1_offset_mlu = src1_mlu + taskId * data_per_core_mlu;
    float* dst_offset_mlu = dst_mlu + taskId * data_per_core_mlu;

    if (taskId == taskDim - 1) {
        data_per_core_mlu = data_last_core_mlu;
    }

    const unsigned int data_nram_num_mlu = 256*256;
    const unsigned int loop_num_mlu = data_per_core_mlu / data_nram_num_mlu;
    const unsigned int rem_nram_num_mlu = data_per_core_mlu % data_nram_num_mlu;  
    
    float *float_src0_nram_mlu = (float *)(nram_buffer);
    float *float_dst_nram_mlu = (float *)(nram_buffer);
    __wram__ float float_src1_nram_mlu[data_nram_num_mlu];

    for (unsigned int i = 0; i < loop_num_mlu; ++i){
        __memcpy(float_src0_nram_mlu, src0_offset_mlu + i * data_nram_num_mlu, data_nram_num_mlu * sizeof(float), GDRAM2NRAM);
        __memcpy(float_src1_nram_mlu, src1_offset_mlu + i * data_nram_num_mlu, data_nram_num_mlu * sizeof(float), GDRAM2WRAM);
        __bang_matmul(float_dst_nram_mlu, float_src0_nram_mlu, float_src1_nram_mlu, 256, 256, 256);
        __memcpy(dst_offset_mlu + i * data_nram_num_mlu, float_dst_nram_mlu, data_nram_num_mlu * sizeof(float), NRAM2GDRAM);
    }
    if (rem_nram_num_mlu != 0){
        __memcpy(float_src0_nram_mlu, src0_offset_mlu + loop_num_mlu * rem_nram_num_mlu, rem_nram_num_mlu * sizeof(float), GDRAM2NRAM);
        __memcpy(float_src1_nram_mlu, src1_offset_mlu + loop_num_mlu * rem_nram_num_mlu, rem_nram_num_mlu * sizeof(float), GDRAM2WRAM);
        __bang_matmul(float_dst_nram_mlu, float_src0_nram_mlu, float_src1_nram_mlu, 256, 256, 256);
        __memcpy(dst_offset_mlu + loop_num_mlu * rem_nram_num_mlu, float_dst_nram_mlu, rem_nram_num_mlu * sizeof(float), NRAM2GDRAM);
    }*/
}


__mlu_global__ void cropKernel(uchar* src, uchar* dst, int h_src, int w_src, int channels,
                               int top, int left, int h_dst, int w_dst) {

    const int rows_per_core_dst = h_dst / taskDim;
    const int rows_last_core_dst = rows_per_core_dst + (h_dst % taskDim);
    const int rows_current_dst = (taskId == taskDim - 1) ? rows_last_core_dst : rows_per_core_dst;

    int size_row_dst = w_dst * channels;
    int size_row_src = w_src * channels;

    int offset_start_rows_dst = rows_per_core_dst * taskId;
    int offset_start_rows_src = top + offset_start_rows_dst;
    // this is already the start position of certain row in crop area
    int offset_start_size_dst = offset_start_rows_dst * size_row_dst;
    int offset_start_size_src = offset_start_rows_src * size_row_src + left * channels;

    // uchar *dst_nram  = (uchar*)(nram_buffer + taskId * MAX_NRAM_SIZE_PER_CORE);
    uchar *dst_nram = (uchar*)nram_buffer;
    uchar *src_gdram = src + offset_start_size_src;
    uchar *dst_gdram = dst + offset_start_size_dst;

    // Firstly move data from GDRAM to NRAM
    // 2D memcpy
    __memcpy(dst_nram, src_gdram, size_row_dst, GDRAM2NRAM, size_row_dst, size_row_src, rows_current_dst);

    // Then move data from NRAM to GDRAM
    __memcpy(dst_gdram, dst_nram, size_row_dst * rows_current_dst, NRAM2GDRAM);
}


extern "C" {
    void initialize() {
        CNRT_CHECK(cnrtSetDevice(0));
        CNRT_CHECK(cnrtQueueCreate(&__queue));
    }

    void release() {
        CNRT_CHECK(cnrtQueueDestroy(__queue));
    }

    void resizeImage(uchar *host_dst, uchar *host_src, int width, int height, int src_height, int src_width,int stepDst,int stepSrc) {
      const int imgnew_size = 3 * width * height;

      float scale_x = static_cast<float>(src_width) / width;
      float scale_y = static_cast<float>(src_height) / height;
      /*unsigned int M = 950;
      unsigned int K = 950;
      unsigned int N = 950;
      float *src0 = (float *)malloc(M * K * sizeof(float));
      float *src2 = (float *)malloc(K * N * sizeof(float));

      for (unsigned int i = 0; i < M * K; i++) {
          src0[i] = (float)(i + 1);
      }
      for (unsigned int i = 0; i < K * N; i++) {
          src2[i] = (float)(i + 1);
      }

      float *src0_mlu;
      float *src1_mlu;
      float *dst_mlu;
      CNRT_CHECK(cnrtMalloc((void**)&src0_mlu, M * K * sizeof(float)));
      CNRT_CHECK(cnrtMalloc((void**)&src1_mlu, K * N * sizeof(float)));
      CNRT_CHECK(cnrtMalloc((void**)&dst_mlu, M * N * sizeof(float)));
    
      CNRT_CHECK(cnrtMemcpy(src0_mlu, src0, M * K * sizeof(float), cnrtMemcpyHostToDev));
      CNRT_CHECK(cnrtMemcpy(src1_mlu, src2, K * N * sizeof(float), cnrtMemcpyHostToDev));
      //CNRT_CHECK(cnrtMemcpy(dst_mlu, dst_c, M * N * sizeof(float), cnrtMemcpyHostToDev));*/
      uint32_t *index = (uint32_t *)malloc(imgnew_size*sizeof(uint32_t));
      //#pragma omp parallel for num_threads(39)
      for (int j = 0; j < height; ++j) {
          for (int i = 0; i < width; ++i) {
             int sx = static_cast<int>(i * scale_x);
             int sy = static_cast<int>(j * scale_y);
             sx = fmin(sx, src_width - 1);
             sy = fmin(sy, src_height - 1);
             for (int k = 0; k < 3; ++k)
                 index[j*stepDst+i*3+k] = (sy*stepSrc+sx*3+k);
          }
       }

       uint src_size = src_width * src_height * 3;
       uint dst_size = width * height * 3;

       cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM , 1};
       cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_UNION1;
       uchar* mlu_src;
       CNRT_CHECK(cnrtMalloc((void**)&mlu_src, 3 * src_width * src_height * sizeof(uchar)));

       uchar* mlu_dst;
       CNRT_CHECK(cnrtMalloc((void**)&mlu_dst, imgnew_size * sizeof(uchar)));
       int* src1,* dst1;
       CNRT_CHECK(cnrtMalloc((void**)&src1, 3 * src_width * src_height * sizeof(int)));
       CNRT_CHECK(cnrtMalloc((void**)&dst1, imgnew_size * sizeof(int)));

       uint32_t* mlu_index;
       CNRT_CHECK(cnrtMalloc((void**)&mlu_index, imgnew_size * sizeof(uint32_t)));
       CNRT_CHECK(cnrtMemcpy(mlu_index, index, imgnew_size * sizeof(uint32_t), cnrtMemcpyHostToDev));
       CNRT_CHECK(cnrtMemcpy(mlu_src, host_src, 3 * src_width * src_height * sizeof(uchar), cnrtMemcpyHostToDev));
       resizeNearestKernel<<<dim, ktype,__queue>>>(mlu_dst, mlu_src, mlu_index,src_size, dst_size);

       CNRT_CHECK(cnrtQueueSync(__queue));
       CNRT_CHECK(cnrtMemcpy(host_dst, mlu_dst, imgnew_size * sizeof(uchar), cnrtMemcpyDevToHost));

       cnrtFree(mlu_src);
       cnrtFree(mlu_dst);
       cnrtFree(mlu_index);
       cnrtFree(src1);

       cnrtFree(dst1);
       free(index);
	/*
        cnrtFree(src0_mlu);
        cnrtFree(src1_mlu);
        cnrtFree(dst_mlu);

        free(src0);
        free(src2);*/
        return;
   }

    void adjustContrast(uchar *host_dst, uchar *host_src,  int src_height, int src_width) {
    
        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM , 1};

        const int image_size = src_height * src_width;

        cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_UNION1;

        float alpha = 2.0;
        /*unsigned int M = 730;
        unsigned int K = 730;
        unsigned int N = 730;
        float *src0 = (float *)malloc(M * K * sizeof(float));
        float *src1 = (float *)malloc(K * N * sizeof(float));

        for (unsigned int i = 0; i < M * K; i++) {
            src0[i] = (float)(i + 1);
        }
        for (unsigned int i = 0; i < K * N; i++) {
            src1[i] = (float)(i + 1);
        }

        float *src0_mlu;
        float *src1_mlu;
        float *dst_mlu;
        CNRT_CHECK(cnrtMalloc((void**)&src0_mlu, M * K * sizeof(float)));
        CNRT_CHECK(cnrtMalloc((void**)&src1_mlu, K * N * sizeof(float)));
        CNRT_CHECK(cnrtMalloc((void**)&dst_mlu, M * N * sizeof(float)));
    
        CNRT_CHECK(cnrtMemcpy(src0_mlu, src0, M * K * sizeof(float), cnrtMemcpyHostToDev));
        CNRT_CHECK(cnrtMemcpy(src1_mlu, src1, K * N * sizeof(float), cnrtMemcpyHostToDev));
        //CNRT_CHECK(cnrtMemcpy(dst_mlu, dst_c, M * N * sizeof(float), cnrtMemcpyHostToDev));*/
        uint8_t* mlu_dst;
        uint8_t* mlu_src;

        // allocate device memory
        CNRT_CHECK(cnrtMalloc((void**)&mlu_dst, 3 * image_size * sizeof(uint8_t)));
        CNRT_CHECK(cnrtMalloc((void**)&mlu_src, 3 * image_size * sizeof(uint8_t)));

        // copy host data to device memory
        CNRT_CHECK(cnrtMemcpy(mlu_src, host_src, 3 * image_size * sizeof(uint8_t), cnrtMemcpyHostToDev));

        adjustContrastKernel<<<dim, ktype, __queue>>>(mlu_dst, mlu_src, src_height * src_width * 3, alpha);

        cnrtQueueSync(__queue);

        CNRT_CHECK(cnrtMemcpy(host_dst, mlu_dst, 3 * image_size * sizeof(uint8_t), cnrtMemcpyDevToHost));

	
        cnrtFree(mlu_dst);
        cnrtFree(mlu_src);
        /*cnrtFree(src0_mlu);
        cnrtFree(src1_mlu);
        cnrtFree(dst_mlu);

        free(src0);
        free(src1);*/
        return;
    }

    void adjustBrightness(uchar *host_dst, uchar *host_src,  int src_height, int src_width){

        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM , 1};

        const int image_size = src_height * src_width;

        cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_UNION1;

        float alpha = 2.0;
        /*unsigned int M = 750;
        unsigned int K = 750;
        unsigned int N = 750;
        float *src0 = (float *)malloc(M * K * sizeof(float));
        float *src1 = (float *)malloc(K * N * sizeof(float));

        for (unsigned int i = 0; i < M * K; i++) {
            src0[i] = (float)(i + 1);
        }
        for (unsigned int i = 0; i < K * N; i++) {
            src1[i] = (float)(i + 1);
        }

        float *src0_mlu;
        float *src1_mlu;
        float *dst_mlu;
        CNRT_CHECK(cnrtMalloc((void**)&src0_mlu, M * K * sizeof(float)));
        CNRT_CHECK(cnrtMalloc((void**)&src1_mlu, K * N * sizeof(float)));
        CNRT_CHECK(cnrtMalloc((void**)&dst_mlu, M * N * sizeof(float)));
    
        CNRT_CHECK(cnrtMemcpy(src0_mlu, src0, M * K * sizeof(float), cnrtMemcpyHostToDev));
        CNRT_CHECK(cnrtMemcpy(src1_mlu, src1, K * N * sizeof(float), cnrtMemcpyHostToDev));
        //CNRT_CHECK(cnrtMemcpy(dst_mlu, dst_c, M * N * sizeof(float), cnrtMemcpyHostToDev));
        */  
        uint8_t* mlu_dst;
        uint8_t* mlu_src;

        CNRT_CHECK(cnrtMalloc((void**)&mlu_dst, 3 * image_size * sizeof(uint8_t)));
        CNRT_CHECK(cnrtMalloc((void**)&mlu_src, 3 * image_size * sizeof(uint8_t)));

        CNRT_CHECK(cnrtMemcpy(mlu_src, host_src, 3 * image_size * sizeof(uint8_t), cnrtMemcpyHostToDev));

        adjustBrightnessKernel<<<dim, ktype, __queue>>>(mlu_dst, mlu_src, src_height * src_width * 3, alpha);

        cnrtQueueSync(__queue);

        CNRT_CHECK(cnrtMemcpy(host_dst, mlu_dst, 3 * image_size * sizeof(uint8_t), cnrtMemcpyDevToHost));


        cnrtFree(mlu_dst);
        cnrtFree(mlu_src);
    
        /*cnrtFree(src0_mlu);
        cnrtFree(src1_mlu);
        cnrtFree(dst_mlu);

        free(src0);
        free(src1);*/

        return;
    }

     void to_grayscale(uint8_t *host_dst, uint8_t *host_src, const int img_size, const int num_output_channels=1) {
        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
        cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_BLOCK;

        const int num_input_channels = 3;

        uint8_t *mlu_src;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_src, num_input_channels * img_size * sizeof(uint8_t)));
        
        CNRT_CHECK(cnrtMemcpy(mlu_src, host_src, num_input_channels * img_size * sizeof(uint8_t), cnrtMemcpyHostToDev));

        uint8_t *mlu_dst;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_dst, num_output_channels * img_size * sizeof(uint8_t)));

        gray_kernel<<<dim, func_type, __queue>>>(mlu_dst, mlu_src, img_size, num_output_channels);

        CNRT_CHECK(cnrtQueueSync(__queue));
        CNRT_CHECK(cnrtMemcpy(host_dst, mlu_dst, num_output_channels * img_size * sizeof(uint8_t), cnrtMemcpyDevToHost));

        CNRT_CHECK(cnrtFree(mlu_src));
        CNRT_CHECK(cnrtFree(mlu_dst));
    }

    void pad(uint8_t *host_dst, uint8_t *host_src, uint8_t *padding_buffer, const int src_height, const int src_width, const int top, const int bottom, const int left, const int right) {
        const int img_size = src_height * src_width;
        const int dst_height = src_height + top + bottom;
        const int dst_width = src_width + left + right;

        // Padding the top border
        for (int i = 0; i < top; ++i) {
            memcpy(host_dst + 3 * i * dst_width, padding_buffer, 3 * dst_width * sizeof(uint8_t));
        }

        // Padding the bottom border
        const int loop_num = bottom / top;
        const int rem_rows = bottom % top;
        uint8_t *dst_offset = host_dst + 3 * (dst_height - bottom) * dst_width;
        for (int i = 0; i < loop_num; ++i) {
            memcpy(dst_offset + i * 3 * top * dst_width, host_dst, 3 * top * dst_width * sizeof(uint8_t));
        }
        if (rem_rows > 0) {
            memcpy(dst_offset + loop_num * 3 * top * dst_width, host_dst, 3 * rem_rows * dst_width * sizeof(uint8_t));
        }

        // Padding the left and right border
        if (left != 0 || right != 0) {
            const int max_pad_size = left >= right ? left: right;

            cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
            cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_BLOCK;

            uint8_t *mlu_dst;
            CNRT_CHECK(cnrtMalloc((void**)&mlu_dst, 3 * src_height * dst_width * sizeof(uint8_t)));

            uint8_t *mlu_src;
            CNRT_CHECK(cnrtMalloc((void**)&mlu_src, 3 * img_size * sizeof(uint8_t)));
            CNRT_CHECK(cnrtMemcpy(mlu_src, host_src, 3 * img_size * sizeof(uint8_t), cnrtMemcpyHostToDev));

            uint8_t *mlu_pad;
            CNRT_CHECK(cnrtMalloc((void**)&mlu_pad, 3 * max_pad_size * sizeof(uint8_t)));
            CNRT_CHECK(cnrtMemcpy(mlu_pad, padding_buffer, 3 * max_pad_size * sizeof(uint8_t), cnrtMemcpyHostToDev));

            pad_kernel<<<dim, func_type, __queue>>>(mlu_dst, mlu_src, mlu_pad, src_height, src_width, left, right);

            CNRT_CHECK(cnrtQueueSync(__queue));
            CNRT_CHECK(cnrtMemcpy(host_dst + 3 * top * dst_width, mlu_dst, 3 * src_height * dst_width * sizeof(uint8_t), cnrtMemcpyDevToHost));

            CNRT_CHECK(cnrtFree(mlu_dst));
            CNRT_CHECK(cnrtFree(mlu_src));
            CNRT_CHECK(cnrtFree(mlu_pad));
        }
        else {
            memcpy(host_dst + 3 * top * dst_width, host_src, 3 * img_size * sizeof(uint8_t));
        }
    }

    void perspective(uint8_t *host_dst, uint8_t *host_src, const int height, const int width, const int *startpoints, const int *endpoints, const uint8_t *fill) { 
        float TransformMatrix[9];
        getPerspectiveTransform(endpoints, startpoints, TransformMatrix);

        const int img_size = height * width;
        const int num_input_channels = 3;

        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
        cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_BLOCK;

        uint32_t *mlu_grid;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_grid, 3 * img_size * sizeof(uint32_t)));

        float *mlu_transformMatrix;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_transformMatrix, 9 * sizeof(float)));
        CNRT_CHECK(cnrtMemcpy(mlu_transformMatrix, TransformMatrix, 9 * sizeof(float), cnrtMemcpyHostToDev));

        perspective_kernel<<<dim, func_type, __queue>>>(mlu_grid, mlu_transformMatrix, height, width);

        /*
         * In order to avoid using a large number of IF statements to determine 
         * whether the transformed image points are within the boundary, 
         * MLU maps all points outside the original image boundary to position 0. 
         * However, this may result in incorrect pixel values in the upper left corner of the transformed image, 
         * as this point in the original image has been filled in.
         */
        host_src[0] = fill[0];
        host_src[1] = fill[1];
        host_src[2] = fill[2];

        int buffer_size = 80000;
        const int loop_num = num_input_channels * img_size / buffer_size;
        const int rem_data = num_input_channels * img_size % buffer_size;

        if (loop_num == 0) {
            buffer_size = rem_data;
        }

        uint32_t *offset = nullptr;
        uint32_t *grid[2] = {nullptr, nullptr};
        CNRT_CHECK(cnrtHostMalloc((void **)&(grid[0]), 2 * buffer_size * sizeof(uint32_t)));
        grid[1] = grid[0] + buffer_size;

        CNRT_CHECK(cnrtQueueSync(__queue));

        // uint32_t *grid = (uint32_t *)malloc(3 * img_size * sizeof(uint32_t));
        // CNRT_CHECK(cnrtMemcpy(grid, mlu_grid, 3 * img_size * sizeof(uint32_t), cnrtMemcpyDevToHost));
        // // #pragma omp parallel for
        // for (unsigned int i = 0; i < num_input_channels * img_size; ++i) {
        //     host_dst[i] = host_src[grid[i]];
        // }
        // free(grid);

        CNRT_CHECK(cnrtMemcpy(grid[0], mlu_grid, buffer_size * sizeof(uint32_t), cnrtMemcpyDevToHost));

        for (int t = 1; t < loop_num; ++t) {
            CNRT_CHECK(cnrtMemcpyAsync(grid[t & 0b1], mlu_grid + t * buffer_size, buffer_size * sizeof(uint32_t), __queue, cnrtMemcpyDevToHost));
            offset = grid[(t - 1) & 0b1];
            for (int i = 0; i < buffer_size; ++i) {
                host_dst[i] = host_src[offset[i]];
            }
            host_dst += buffer_size;
            CNRT_CHECK(cnrtQueueSync(__queue));
        }

        if (loop_num != 0) {
            CNRT_CHECK(cnrtMemcpyAsync(grid[loop_num & 0b1], mlu_grid + loop_num * buffer_size, rem_data * sizeof(uint32_t), __queue, cnrtMemcpyDevToHost));
            offset = grid[(loop_num - 1) & 0b1];
            for (int i = 0; i < buffer_size; ++i) {
                host_dst[i] = host_src[offset[i]];
            }
            host_dst += buffer_size;
            CNRT_CHECK(cnrtQueueSync(__queue));
        }

        if (rem_data != 0) {
            offset = grid[loop_num & 0b1];
            for (int i = 0; i < rem_data; ++i) {
                host_dst[i] = host_src[offset[i]];
            }
        }

        CNRT_CHECK(cnrtFreeHost(grid[0]));
        CNRT_CHECK(cnrtFree(mlu_grid));
        CNRT_CHECK(cnrtFree(mlu_transformMatrix));
    }

    void flip(uint8_t *host_dst, uint8_t *host_src, const int height, const int width) {
        const int img_size = height * width;
        // cnrtQueue_t queue;
        // CNRT_CHECK(cnrtSetDevice(0));
        // CNRT_CHECK(cnrtQueueCreate(&queue));
        cnrtDim3_t dim = {static_cast<unsigned int>(height), 1, 1};
        cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_BLOCK;
        uint8_t *mlu_src;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_src, 3 * img_size * sizeof(uint8_t)));
        CNRT_CHECK(cnrtMemcpy(mlu_src, host_src, 3 * img_size * sizeof(uint8_t), cnrtMemcpyHostToDev));

        uint8_t *mlu_dst;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_dst, 3 * img_size * sizeof(uint8_t)));

        Flip_Kernel<<<dim, func_type, __queue>>>(mlu_dst, mlu_src, width, height);

        CNRT_CHECK(cnrtQueueSync(__queue));

        CNRT_CHECK(cnrtMemcpy(host_dst, mlu_dst, 3 * img_size * sizeof(uint8_t), cnrtMemcpyDevToHost));

        CNRT_CHECK(cnrtFree(mlu_dst));
        CNRT_CHECK(cnrtFree(mlu_src));
        
        // CNRT_CHECK(cnrtQueueDestroy(queue));
    }

    void rotate(uint8_t* src, uint8_t* dst, const int src_height, const int src_width,
                const int dst_height, const int dst_width, const int channels, const double angle) {
        // Calculate angle in radians
        float radians = angle * PI / 180.0;

        // Compute sine and cosine of the angle
        float cos_angle = (float)cos(radians);
        float sin_angle = (float)sin(radians);

        int src_size = src_width * src_height;
        int dst_size = dst_width * dst_height;
        
        // Calculate the center of the images
        float cx = src_width / 2.0;
        float cy = src_height / 2.0;

        float new_cx = dst_width / 2.0;
        float new_cy = dst_height / 2.0;

        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
        cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_BLOCK;

        int* mlu_idxs;
        int* host_idxs = (int *)malloc(dst_size * sizeof(int));;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_idxs, dst_size * sizeof(int)));

        Kernel_rotate<<<dim, ktype, __queue>>>(mlu_idxs, src_size,
                                    src_width, src_height, dst_width, dst_height,
                                    cos_angle, sin_angle, cx, cy, new_cx, new_cy);
        // Allocate memory for the destination image
        // cv::Mat dst = cv::Mat::zeros(dst_height, dst_width, src.type()); // cost about 11ms

        // uchar *host_src = src.isContinuous()? src : (uchar *)src.clone().data;
        uint8_t* host_src = src;
        for (int i = 0; i < 3; i++) *(host_src) = 0; // pre-prepared for outbound values.
        // uchar *host_dst = (uchar*)dst.data;
        uint8_t *host_dst = dst;

        cnrtQueueSync(__queue);
        // less than 14ms
        CNRT_CHECK(cnrtMemcpyAsync(host_idxs, mlu_idxs, dst_size * sizeof(int), __queue, cnrtMemcpyDevToHost)); 
        // CNRT_CHECK(cnrtMemcpy(host_idxs, mlu_idxs, dst_size * sizeof(int),cnrtMemcpyDevToHost));
        // cnrtQueueSync(__queue);
        usleep(1000);

        // it's weird that when dst has initiated, this loop run faster compared to when it hasn't.
        // greater than 16ms
        host_src[0] = host_src[1] = host_src[2] = 0;
        for (int i = 0; i < dst_size; i++) {
            int idx_src = host_idxs[i] * channels;
            int idx_curr = i * channels;
            for (int j = 0; j < 3; j++) {
                host_dst[idx_curr + j] = host_src[idx_src + j];
            }
        }

        // free memory
        cnrtFree(mlu_idxs);
        free(host_idxs);
        // return dst;
    }

    void affine(uint8_t* src, uint8_t* dst, const int height, const int width, const int channels, const float angle, float sx, float sy, const float tx, const float ty, const float shear_x, const float shear_y)
    {
        float a, b, c;
        float d, e, f;

        sx = 1 / sx;
        sy = 1 / sy;

        int src_size = width * height, dst_size = src_size;

        float theta = angle * PI / 180.0;
        // float theta = angle * 3.14 / 180.0;
        float cx = width / 2.0;
        float cy = height / 2.0;

        a = sx * cos(theta) + shear_y * sy * sin(theta);
        b = -sy * sin(theta) + shear_y * sy * cos(theta);
        d = shear_x * sx * cos(theta) + sx * sin(theta);
        e = shear_x * -sy * sin(theta) + sy * cos(theta);

        // Apply translation to move the image back to its original position after rotating around the center
        c = -a * cx - b * cy + cx + tx;
        f = -d * cx - e * cy + cy + ty;

        // facilities
        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
        cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_BLOCK;

        int *mlu_idxs;
        int *host_idxs = (int *)malloc(dst_size * sizeof(int));
        CNRT_CHECK(cnrtMalloc((void **)&mlu_idxs, dst_size * sizeof(int)));

        Kernel_affine<<<dim, ktype, __queue>>>(mlu_idxs, src_size,
                                            a, b, c, d, e, f,
                                            height, width, channels);
                                            
        // cv::Mat dst = cv::Mat::zeros(height, width, src.type()); // cost about 11ms
        // uchar *host_src = src.isContinuous() ? (uchar *)src.data : (uchar *)src.clone().data;
        // uchar *host_dst = (uchar *)dst.data;
        uint8_t* host_src = src;
        uint8_t* host_dst = dst;

        cnrtQueueSync(__queue);
        // less than 14ms
        CNRT_CHECK(cnrtMemcpyAsync(host_idxs, mlu_idxs, dst_size * sizeof(int), __queue, cnrtMemcpyDevToHost));
        // cnrtQueueSync(queue);
        usleep(1000);

        // greater than 16ms
        host_src[0] = host_src[1] = host_src[2] = 0;
        for (int i = 0; i < dst_size; i++)
        {
            int idx_src = host_idxs[i] * channels;
            int idx_curr = i * channels;
            for (int j = 0; j < 3; j++)
            {
                host_dst[idx_curr + j] = host_src[idx_src + j];
            }
        }

        cnrtFree(mlu_idxs);
        free(host_idxs);
    } 

    // cv::Mat erase(uchar* src, uchar* dst, int src_width, int src_height, int channels, int top, int left, int height, int width, uchar v, bool inplace) {
    void erase(uint8_t* src, uint8_t* dst, int src_width, int src_height, int channels, int top, int left, int height, int width, uint8_t v) {
        if (left < 0 || left > src_width || top < 0 || top > src_height ||
            height < 0 || width < 0 || left + width > src_width || top + height > src_height) {
                printf("Erase area is not correct.\n");
                return;
        }

        int src_area = src_height * src_width;
        int dst_area = height * width;

        int dst_size = src_width * height * channels * sizeof(uint8_t);

        // uchar *host_src = src.isContinuous() ? (uchar *)src.data : (uchar *)src.clone().data;
        uint8_t *host_src = src;

        // uchar* host_data = (uchar*)p_dst->data + (top * src_width + left) * channels;
        uint8_t* host_data = dst + (top * src_width + left) * channels;
        if (height < 24) {
            for (int i = 0; i < height; i++) {
                memset(host_data + i * src_width * channels, 0, width * channels * sizeof(uint8_t));
            }
            return;
        }

        uint8_t* mlu_data;
        CNRT_CHECK(cnrtMalloc((void**)&mlu_data, dst_size));
        CNRT_CHECK(cnrtMemcpy(mlu_data, host_data, dst_size, cnrtMemcpyHostToDev));

        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
        cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_BLOCK;

        Kernel_erase<<<dim, ktype, __queue>>>(
            mlu_data, v, src_width, width, height, channels);

        cnrtQueueSync(__queue);
        CNRT_CHECK(cnrtMemcpy(host_data, mlu_data, dst_size, cnrtMemcpyDevToHost));

        cnrtFree(mlu_data);
    }

        void crop(uchar *dst, uchar *src, int src_height, int src_width, int channels, int top, int left, int height, int width) {
        if (left < 0 || left > src_width || top < 0 || top > src_height ||
            height < 0 || width < 0 || left + width > src_width || top + height > src_height) {
                printf("Crop area is not correct.\n");
                return;
        }

        if (height < CLUSTER_NUM * CORE_NUM_PER_CLUSTER) {
            printf("The height of crop area is supposed to be equal or greater than %d.\n", CLUSTER_NUM * CORE_NUM_PER_CLUSTER);
            return;
        }
        
        int src_area = src_height * src_width;
        int dst_area = height * width;

        // data movement
        // presume src is continuous
        uchar *mlu_dst;
        uchar *mlu_src;
        CNRT_CHECK(cnrtMalloc((void **)&mlu_dst, dst_area * channels)); // cost about 5ms
        CNRT_CHECK(cnrtMalloc((void **)&mlu_src, src_area * channels));
        CNRT_CHECK(cnrtMemcpy(mlu_src, src, src_area * channels, cnrtMemcpyHostToDev));

        cnrtDim3_t dim = {CORE_NUM_PER_CLUSTER, CLUSTER_NUM, 1};
        cnrtFunctionType_t ktype = CNRT_FUNC_TYPE_BLOCK;

        cropKernel<<<dim, ktype, __queue>>>(
            mlu_src, mlu_dst, src_height, src_width, channels, top, left, height, width);

        cnrtQueueSync(__queue);

        CNRT_CHECK(cnrtMemcpy(dst, mlu_dst, dst_area * channels * sizeof(uchar), cnrtMemcpyDevToHost));
        
        cnrtFree(mlu_dst);
    }

    void centerCrop(uchar *dst, uchar *src, int src_height, int src_width, int channels, int height, int width) {
        int top = (src_height - height) / 2;
        int left = (src_width - width) / 2;
        crop(dst, src, src_height, src_width, channels, top, left, height, width);
    }


    void randomCrop(uchar *dst, uchar *src, int src_height, int src_width, int channels, int height, int width) {
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_int_distribution<int> distrib_left(0, src_width - width);
        std::uniform_int_distribution<int> distrib_top(0, src_height - height);

        int left = distrib_left(gen);
        int top = distrib_top(gen);

        crop(dst, src, src_height, src_width, channels, top, left, height, width);
    }


}
